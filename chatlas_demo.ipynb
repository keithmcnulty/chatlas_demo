{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b598728966cda6c7",
   "metadata": {},
   "source": [
    "## The `chatlas` package for a consistent LLM interface and workflow\n",
    "\n",
    "One of the frustrations of working with different LLM providers is the difference in API structures.  This has historically meant that developers have had to code up their LLM workflows quite differently if they were working with, say, OpenAI versus Anthropic or Llama.\n",
    "\n",
    "The `chatlas` package attempts to overcome this by offering a set of classes and methods that have greater alignment across LLM providers.  This means that starting a chat, or using tool calling or other services will look the same or very similar, no matter which LLM provider you are using.  For those familiar, `chatlas` is basically the Python equivalent of R's `ellmer` package.\n",
    "\n",
    "The following is a short illustratory demo of some of the features of `chatlas`.\n",
    "\n",
    "### Starting a chat session - OpenAI example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages and key environment variables\n",
    "from dotenv import load_dotenv\n",
    "from chatlas import ChatOpenAI, ChatAnthropic, ChatOllama\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "INSTANCE_ID = os.getenv('INSTANCE_ID')\n",
    "API_KEY = os.getenv('API_KEY')\n",
    "BASE_URL_STEM = os.getenv('BASE_URL_STEM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546d0dea3ecdc27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up an openai chat client\n",
    "PROVIDER = \"openai\"\n",
    "BASE_URL = f\"https://{PROVIDER}.{BASE_URL_STEM}/{INSTANCE_ID}/v1\"\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model = \"gpt-4o\",\n",
    "    api_key = API_KEY,\n",
    "    base_url = BASE_URL,\n",
    "    system_prompt = \"You are a friendly but terse assistant.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de449303d11dbb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start a chat app\n",
    "chat.app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233116d1326bace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat in the console\n",
    "chat.console()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea91e7f6813d261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# programmatic chat\n",
    "chat.chat(\"What exactly is a spirit vegetable?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fba4e5b0fc732ef",
   "metadata": {},
   "source": [
    "### Tool (function) calling - OpenAI example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529b5c906fcffc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool (function) calling - function to get current temperature\n",
    "import requests\n",
    "\n",
    "# function to get the current temperature in a place\n",
    "def get_current_temperature(place: str) -> str:\n",
    "  \"\"\"Get the current temperature in a given place.\"\"\"\n",
    "  base_url = f\"https://wttr.in/{place}?format=j1\"\n",
    "  response = requests.get(base_url)\n",
    "  data = response.json()\n",
    "  return f\"The current temperature in {place} is {data['current_condition'][0]['temp_C']} degrees Celsius\"\n",
    "\n",
    "# test the function\n",
    "get_current_temperature(\"London\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65defb7d518fddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# register the function with your chat\n",
    "chat.register_tool(get_current_temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ad12d2a1ff5161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the chat can use it\n",
    "chat.chat(\"I'm in Atlanta today and I'm told I should wear warm clothes.  What do you think?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa6cc578725c5ed",
   "metadata": {},
   "source": [
    "### Structured data extraction - OpenAI example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67578dd3cd639983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling structured data out of text\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    pets: int\n",
    "    skills: list[str]\n",
    "\n",
    "chat.extract_data(\n",
    "  \"My name is Keith.  I have two cats and one dog named Bertie.  I am very good at Math and Computer Games\", \n",
    "  data_model=Person,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccccb8701a354ccf",
   "metadata": {},
   "source": [
    "### Start a new chat - Anthropic example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76591f56b64f261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now try a Anthropic chat client- note similar but not 100% identical to OpenAI\n",
    "PROVIDER = \"anthropic\"\n",
    "BASE_URL = f\"https://{PROVIDER}.{BASE_URL_STEM}/{INSTANCE_ID}\"\n",
    "\n",
    "chat = ChatAnthropic(\n",
    "    api_key = API_KEY,\n",
    "    system_prompt = \"You are a friendly but terse assistant.\",\n",
    "    kwargs = {\"base_url\": BASE_URL}  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70ea9b886585d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# programmatic chat\n",
    "chat.chat(\"Which integer is commonly quoted as the answer to the meaning of life?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c96a9651a03fb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# register tool\n",
    "chat.register_tool(get_current_temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4c3154775c5434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check tool use\n",
    "chat.chat(\"My sister is heading to the capital of Norway next week?  How should she pack?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd70896b849393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  extract structured data\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    pets: int\n",
    "    areas_of_expertise: list[str]\n",
    "    qualifications: list[str]\n",
    "\n",
    "chat.extract_data(\n",
    "  \"\"\"\n",
    "  My name is Keith.  I had two cats and one dog named Bertie, but I recently sold the two cats.  I have a PhD in Pure Mathematics, and I am also a holder of the Licentiate Performing Diploma from Trinity College of Music in London, taking my final exams in the Recorder.\n",
    "  \"\"\", \n",
    "  data_model = Person,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584f688d80d5c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update structured information during chat session\n",
    "chat.extract_data(\n",
    "  \"\"\"\n",
    "  Oh it's Keith again.  I'm sorry, I'm so dumb.  I forgot to mention I also have a new puppy which we only just picked up this week.\n",
    "  \"\"\", \n",
    "  data_model = Person,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11066ac7cdd4c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update again\n",
    "chat.extract_data(\n",
    "  \"\"\"\n",
    "  It's Keith again.  I just spoke to my wife and she left the door open and the puppy ran out on the street and got killed.  It's a bad day.\n",
    "  \"\"\", \n",
    "  data_model = Person,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbaa26f33279b2a",
   "metadata": {},
   "source": [
    "### New chat session with local model using `ollama`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27732f5e50317742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local ollama model\n",
    "chat = ChatOllama(\n",
    "    model = \"llama3.1:8b\",\n",
    "    system_prompt = \"You are a friendly but terse assistant.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f962533a0b10ae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# programmatic chat\n",
    "chat.chat(\"Explain Buddhism in two sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc03b776b958a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data using earlier data model\n",
    "chat.extract_data(\n",
    "      \"\"\"\n",
    "  My name is Keith.  I had two cats and one dog named Bertie, but I recently sold the two cats.  I have a PhD in Pure Mathematics, and I am also a holder of the Licentiate Performing Diploma from Trinity College of Music in London, taking my final exams in the Recorder.\n",
    "  \"\"\", \n",
    "  data_model = Person,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c877db11aa0a14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# register temperature tool\n",
    "chat.register_tool(get_current_temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c8f9dea04b01db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use temperature tool\n",
    "chat.chat(\"I'm heading to Tasmania tomorrow but I forgot my sunscreen.  Should I be concerned?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatlas_demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
